{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b23df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build-in imports\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "# 3rd party imports\n",
    "import json\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "from pm4py.objects.log.obj import EventLog\n",
    "from pm4py.objects.log.util import sampling\n",
    "from pm4py.objects.process_tree import obj as pt\n",
    "from pm4py.algo.evaluation.simplicity import algorithm as simplicity_alg\n",
    "from pm4py.algo.evaluation.generalization import algorithm as generalization_alg\n",
    "\n",
    "# DPIM imports (from the DPIM repo)\n",
    "sys.path.insert(0, os.path.abspath(\"./DPIM\")) # Fixes an issue with importing\n",
    "\n",
    "from DPIM.main import DPIM\n",
    "from DPIM.utils import eventLog_parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c122e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_log_hyperparameters(\n",
    "    results_filename: str = \"./DPIM/evaluation_results/Evaluation_Results_DPIM.xlsx\",\n",
    "    event_log_dir: str = \"./Evaluation Logs\"\n",
    ") -> dict:\n",
    "    # The authors of the DPIM paper save their experiments' hyperparameters and results in this file \n",
    "    df_raw: pd.DataFrame = pd.read_excel(\n",
    "        io=results_filename,\n",
    "        header=[0, 1]  # two-row header\n",
    "    )\n",
    "\n",
    "    df: pd.DataFrame = df_raw.copy()\n",
    "\n",
    "    df.columns = [\n",
    "        f\"{a}_{b}\".strip(\"_\")\n",
    "        for a, b in df.columns\n",
    "    ]\n",
    "\n",
    "    df: pd.DataFrame = df.dropna(subset=[\"Event Logs_Event Log\"])\n",
    "    df: pd.DataFrame = df.reset_index(drop=True)\n",
    "\n",
    "    event_log_hyperparameters: dict = {}\n",
    "\n",
    "    for file in os.listdir(event_log_dir):\n",
    "        if not file.endswith(\".gz\"):\n",
    "            continue\n",
    "\n",
    "        log_name: str = Path(file).name.removesuffix(\".xes.gz\")\n",
    "        row = df.loc[df[\"Event Logs_Event Log\"] == log_name]\n",
    "\n",
    "        lower: int = int(row[\"Hyperparameters_Lower\"].iloc[0])\n",
    "        upper: int = int(row[\"Hyperparameters_Upper\"].iloc[0])\n",
    "        fitness_threshold: float = float(row[\"Hyperparameters_Fitness\"].iloc[0])\n",
    "        \n",
    "        event_log_hyperparameters[log_name] = {\n",
    "            \"lower_bound\": lower,\n",
    "            \"upper_bound\": upper,\n",
    "            \"fitness_threshold\": fitness_threshold\n",
    "        }\n",
    "    \n",
    "    return event_log_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ebebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dfr_bounds(log: EventLog, margin: int = 15) -> tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Compute lower and upper bounds for DFR selection based on the actual\n",
    "    directly-follows relation in the sampled log.\n",
    "    \n",
    "    This follows the approach from main.py where bounds are based on the\n",
    "    number of activity pairs that actually occur in the log.\n",
    "    \n",
    "    Args:\n",
    "        log: PM4Py EventLog (potentially sampled)\n",
    "        margin: Number of edges to add/subtract from the count (default: 15)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (lower_bound, upper_bound)\n",
    "    \"\"\"\n",
    "    activities: dict = pm4py.get_event_attribute_values(log, 'concept:name')\n",
    "    num_acts: int = len(activities)\n",
    "    \n",
    "    # Build the DFR with BINARY counting (as DPIM does in Algorithm 2, lines 5-7)\n",
    "    # Count: \"in how many traces does this edge appear?\"\n",
    "    edge_trace_counts = {}\n",
    "    \n",
    "    for trace in log:\n",
    "        # Get unique edges in this trace (binary: 0 or 1 per trace)\n",
    "        edges_in_trace = set()\n",
    "        activities_in_trace = [event['concept:name'] for event in trace]\n",
    "        \n",
    "        # Add START edges\n",
    "        if activities_in_trace:\n",
    "            edges_in_trace.add(('START', activities_in_trace[0]))\n",
    "        \n",
    "        # Add internal edges\n",
    "        for i in range(len(activities_in_trace) - 1):\n",
    "            edges_in_trace.add((activities_in_trace[i], activities_in_trace[i+1]))\n",
    "        \n",
    "        # Add END edges\n",
    "        if activities_in_trace:\n",
    "            edges_in_trace.add((activities_in_trace[-1], 'END'))\n",
    "        \n",
    "        # Binary count: each edge appears at most once per trace\n",
    "        for edge in edges_in_trace:\n",
    "            edge_trace_counts[edge] = edge_trace_counts.get(edge, 0) + 1\n",
    "    \n",
    "    # Count edges that appear in at least one trace\n",
    "    num_edges_with_frequency = len([cnt for cnt in edge_trace_counts.values() if cnt > 0])\n",
    "    \n",
    "    # Apply margin BEFORE rounding\n",
    "    lower = num_edges_with_frequency - margin\n",
    "    upper = num_edges_with_frequency + margin\n",
    "    \n",
    "    # Apply constraints\n",
    "    lower = max(num_acts, lower)\n",
    "    upper = min((num_acts ** 2) - 1, upper)\n",
    "    \n",
    "    # Round to nearest multiple of 5\n",
    "    lower = 5 * round(lower / 5)\n",
    "    upper = 5 * round(upper / 5)\n",
    "    \n",
    "    # Final sanity checks\n",
    "    if lower < num_acts or lower >= upper:\n",
    "        lower = num_acts\n",
    "    if upper > (num_acts ** 2) - 1 or upper <= lower or upper < num_acts:\n",
    "        upper = (num_acts ** 2) - 1\n",
    "    \n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006d5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpim_tree_from_log(log: EventLog, dpim_cfg: dict):\n",
    "    \"\"\"\n",
    "    Build a PM4Py ProcessTree using DPIM for a given PM4Py EventLog.\n",
    "    \n",
    "    Args:\n",
    "        log: PM4Py EventLog object\n",
    "        dpim_cfg: Configuration dict with keys:\n",
    "          - no_dp: bool (if True => epsilon=100000, DP disabled)\n",
    "          - epsilon: float (privacy parameter, default 1.0)\n",
    "          - fitness_threshold: float (minimum fitness, default 0.95)\n",
    "          - lower: int | None (lower bound for DFR selection)\n",
    "          - upper: int | None (upper bound for DFR selection)\n",
    "    \n",
    "    Returns:\n",
    "        pm4py ProcessTree object\n",
    "        \n",
    "    Raises:\n",
    "        RuntimeError: If DPIM fails to construct a valid tree\n",
    "        ValueError: If epsilon is invalid when DP is enabled\n",
    "    \"\"\"\n",
    "    no_dp: bool = bool(dpim_cfg.get(\"no_dp\", False))\n",
    "    epsilon: float = float(dpim_cfg.get(\"epsilon\", 1.0))\n",
    "    fitness_threshold: float = float(dpim_cfg.get(\"fitness_threshold\", 0.95))\n",
    "    lower: int = dpim_cfg.get(\"lower\", None)\n",
    "    upper: int = dpim_cfg.get(\"upper\", None)\n",
    "\n",
    "    # Validate epsilon\n",
    "    if not no_dp and epsilon <= 0:\n",
    "        raise ValueError(\"epsilon must be positive when DP is enabled\")\n",
    "\n",
    "    # DPIM preprocessing (as used in main.py)\n",
    "    permutations, traceList, num_acts = eventLog_parsing.xesFile().createPermutations_XES(event_log=log)\n",
    "\n",
    "    # Bounds: mirror the logic from main.py defaults\n",
    "    if lower is None:\n",
    "        lower = num_acts\n",
    "    if upper is None:\n",
    "        upper = (num_acts ** 2) - 1\n",
    "\n",
    "    miner = DPIM()\n",
    "    miner.fit_trehsold = fitness_threshold\n",
    "    miner.lower_bound = lower\n",
    "    miner.upper_bound = upper\n",
    "\n",
    "    if no_dp:\n",
    "        miner.DP = False\n",
    "         # IMPORTANT: do NOT set 100000 here otherwise recursion happens\n",
    "        eps: float = float(dpim_cfg.get(\"epsilon\", 1.0))\n",
    "    else:\n",
    "        miner.DP = True\n",
    "        eps: float = epsilon\n",
    "\n",
    "    tree: pt.ProcessTree = miner.create_tree(\n",
    "        permutations=permutations,\n",
    "        traceList=traceList,\n",
    "        epsilon=eps,\n",
    "        event_log=log\n",
    "    )\n",
    "\n",
    "    print(\"============== TREE VIA DPIM CREATED ==============\")\n",
    "\n",
    "    # Handle return values\n",
    "    if tree is False:\n",
    "        raise RuntimeError(\n",
    "            \"✗ DPIM rejection sampling did not find a tree meeting the fitness threshold. \"\n",
    "            \"Try lowering fitness_threshold or increasing epsilon.\"\n",
    "        )\n",
    "    if tree is None:\n",
    "        raise RuntimeError(\n",
    "            \"✗ DPIM tree construction failed (likely due to recursion limit). \"\n",
    "            \"The model may be too complex for the selected edges.\"\n",
    "        )\n",
    "\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506857e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(log, mode: str = \"pm4py_im\", dpim_cfg: dict | None = None) -> list[float]:\n",
    "    \"\"\"\n",
    "    This function takes a log for which a process tree is discovered and metrics are computed.\n",
    "    The log is a required parameter and the rest are optional. If only a log is provided the standard IM\n",
    "    via `pm4py` is used. Otherwise, the DPIM process tree can be build with either privacy or no privacy. \n",
    "    \n",
    "    :param log: The Event Log for which metrics like fitness, precision, etc are computed.\n",
    "    :param mode: 'pm4py_im' (baseline inductive miner via PM4Py), 'dpim' (DPIM process tree; configure via dpim_cfg)\n",
    "    :param dpim_cfg: Contains values like epsilon, fitness threshold, lower- and upper bound.\n",
    "    :return: Returns a list of metrics in this order - fitness, precision, simplicity, generalization.\n",
    "    :rtype: list[float]\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1) Discover a process tree depending on mode\n",
    "    if mode == \"pm4py_im\":\n",
    "        tree: pt.ProcessTree = pm4py.discover_process_tree_inductive(log)\n",
    "        print(\"============== TREE VIA PM4Py CREATED ==============\")\n",
    "    elif mode == \"dpim\":\n",
    "        if dpim_cfg is None:\n",
    "            raise ValueError(\"When running DPIM a configuration needs to be passed!\")\n",
    "        tree: pt.ProcessTree = dpim_tree_from_log(log, dpim_cfg)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode='{mode}'. Use 'pm4py_im' or 'dpim'.\")\n",
    "    \n",
    "    # 2) Convert tree -> Petri net\n",
    "    net, im, fm = pm4py.convert_to_petri_net(tree)\n",
    "    print(\"============== PETRI NET CREATED ==============\")\n",
    "    \n",
    "    # 3) Compute metrics\n",
    "   \n",
    "    # Fitness should be calculated when privacy is selected, otherwise no (see xlsx results in DPIM)\n",
    "    fitness = 1\n",
    "    \n",
    "    # Differentially Private Inductive Miner with privacy (epsilon != 100_000, no_dp=False)\n",
    "    if dpim_cfg is not None and dpim_cfg[\"no_dp\"] is False:\n",
    "        fitness = pm4py.fitness_token_based_replay(log, net, im, fm)['log_fitness']\n",
    "        \n",
    "    precision = pm4py.precision_token_based_replay(log, net, im, fm)  \n",
    "    simplicity = simplicity_alg.apply(net)                    \n",
    "    generalization = generalization_alg.apply(log, net, im, fm)\n",
    "    \n",
    "    print(\"============== METRICS COMPUTED ==============\")\n",
    "    \n",
    "    return fitness, precision, simplicity, generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a390b6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Iterate over all Event Logs used for evaluation in the DPIM paper and compute metrics for all variations:\n",
    "\n",
    "IM using pm4py, DPIM with no privacy, DPIM with epsilon=3, DPIM with epsilon=1, DPIM with epsilon=0.1\n",
    "\"\"\"\n",
    "\n",
    "hyperparameters: dict = get_event_log_hyperparameters()\n",
    "evaluation_results: list[dict] = []\n",
    "\n",
    "directory: str = \"./Evaluation Logs\"\n",
    "log_files: list[str] = [f for f in os.listdir(directory) if f.endswith(\".gz\")]\n",
    "\n",
    "sampling_fraction: float = float(input(\"Please enter a sampling fraction: \"))\n",
    "\n",
    "for idx, file in enumerate(log_files, 1):\n",
    "    filename: str = os.path.join(directory, file)\n",
    "    log_name: str = Path(file).name.removesuffix(\".xes.gz\")\n",
    "    \n",
    "    try:\n",
    "        # Load the full log (*.xes.gz)\n",
    "        log = pm4py.read_xes(filename)\n",
    "   \n",
    "        if log_name == \"BPI Challenge 2017\":\n",
    "            sampling_fraction = 0.01 # Since this event log is huge (over 31700 traces)\n",
    "        \n",
    "        # Sample the data, since it's too big and it takes long time to compute   \n",
    "        sample_size: int = math.ceil(len(log) * sampling_fraction)\n",
    "        sampled_log: EventLog = sampling.sample_log(log, no_traces=sample_size)\n",
    "        \n",
    "        print(f\"============== PROCESSING {log_name} ==============\")\n",
    "        print(f\"============== SAMPLE SIZE: {sample_size} FROM ORIGINAL {len(log)} ==============\")\n",
    "        \n",
    "        # Use this if not sampling\n",
    "        # lower_bound: int = hyperparameters[log_name][\"lower_bound\"]\n",
    "        # upper_bound: int = hyperparameters[log_name][\"upper_bound\"]\n",
    "        \n",
    "        # Compute bounds based on the SAMPLED log's DFR\n",
    "        lower_bound, upper_bound = compute_dfr_bounds(sampled_log, margin=15)\n",
    "        fitness_threshold: float = hyperparameters[log_name][\"fitness_threshold\"]\n",
    "\n",
    "        print(f\"Hyperparameters:\")\n",
    "        print(f\"\\tlower bound {lower_bound}\")\n",
    "        print(f\"\\tupper bound {upper_bound}\")\n",
    "        print(f\"\\tfitness threshold {fitness_threshold}\")\n",
    "        \n",
    "        # --- PM4Py Inductive Miner ---\n",
    "        pm4py_fitness, pm4py_precision, pm4py_simplicity, pm4py_generalization = compute_metrics(sampled_log)\n",
    "        \n",
    "        # --- DPIM (no privacy) --- (Tests correctness compared to IM)\n",
    "        no_dp_fitness, no_dp_precision, no_dp_simplicity, no_dp_generalization = compute_metrics(\n",
    "            sampled_log,\n",
    "            mode=\"dpim\",\n",
    "            dpim_cfg={\n",
    "                \"no_dp\": True,\n",
    "                \"lower\": lower_bound,\n",
    "                \"upper\": upper_bound,\n",
    "                \"fitness_threshold\": fitness_threshold\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # --- DPIM with privacy --- (Tests privacy gain and utility loss)\n",
    "        epsilon_values = [3., 1., 0.1] # The values explicitly used in the evaluation results\n",
    "        epsilon_values_results: list[dict] = {}\n",
    "        n: int = 10 # In the DPIM results they perform it with n=100\n",
    "        decimal_points: int = 4\n",
    "        for idx in range(n):\n",
    "            print(f\"============== ITERATION {idx+1} OUT OF {n} ==============\")\n",
    "            current_epsilon_values_results: dict = {}\n",
    "            for eps in epsilon_values:\n",
    "                try:\n",
    "                    dp_fitness, dp_precision, dp_simplicity, dp_generalization = compute_metrics(\n",
    "                        sampled_log,\n",
    "                        mode=\"dpim\",\n",
    "                        dpim_cfg={\n",
    "                            \"no_dp\": False,\n",
    "                            \"epsilon\": eps,\n",
    "                            \"lower\": lower_bound,\n",
    "                            \"upper\": upper_bound,\n",
    "                            \"fitness_threshold\": fitness_threshold\n",
    "                        }\n",
    "                    )\n",
    "                \n",
    "                    current_epsilon_values_results[f\"eps_{eps:g}\"] = {\n",
    "                        \"fitness\": round(dp_fitness, decimal_points),\n",
    "                        \"precision\": round(dp_precision, decimal_points),\n",
    "                        \"simplicity\": round(dp_simplicity, decimal_points),\n",
    "                        \"generalization\": round(dp_generalization, decimal_points),\n",
    "                    }\n",
    "                except RuntimeError as re:\n",
    "                    print(re)\n",
    "                    current_epsilon_values_results[f\"eps_{eps:g}\"] = None\n",
    "                    \n",
    "            epsilon_values_results[idx] = current_epsilon_values_results\n",
    "            \n",
    "        evaluation_results.append({\n",
    "            \"file\": log_name,\n",
    "\n",
    "            \"pm4py_im\": {\n",
    "                \"fitness\": round(pm4py_fitness, decimal_points),\n",
    "                \"precision\": round(pm4py_precision, decimal_points),\n",
    "                \"simplicity\": round(pm4py_simplicity, decimal_points),\n",
    "                \"generalization\": round(pm4py_generalization, decimal_points),\n",
    "            },\n",
    "\n",
    "            \"dpim_no_dp\": {\n",
    "                \"fitness\": round(no_dp_fitness, decimal_points),\n",
    "                \"precision\": round(no_dp_precision, decimal_points),\n",
    "                \"simplicity\": round(no_dp_simplicity, decimal_points),\n",
    "                \"generalization\": round(no_dp_generalization, decimal_points),\n",
    "            },\n",
    "            \n",
    "            \"dpim_dp\": epsilon_values_results\n",
    "        })\n",
    "\n",
    "        print(f\"============== METRICS FOR {log_name} computed ==============\")\n",
    "    except KeyboardInterrupt as ki:\n",
    "        print(f\"\\n✗ PROGRAM WAS INTERRUPTED ...\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ FAILED to process {log_name}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b715552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has to be 14\n",
    "print(f\"Number of logs processed: {len(evaluation_results)}\")\n",
    "\n",
    "# Save results\n",
    "with open(\"BPIC15_2.json\", \"w\") as f:\n",
    "    json.dump(evaluation_results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daae248",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
